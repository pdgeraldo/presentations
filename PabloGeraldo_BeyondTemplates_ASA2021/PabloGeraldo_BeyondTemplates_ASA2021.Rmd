---
title: "Moving beyond templates of empirical research"
subtitle: "(A guide to graphical models for the skeptic)"
author: "Pablo Geraldo (pdgeraldo@ucla.edu)"
institute: "ASA, Quantitative Methodology Session"
date: "August 9, 2021"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      ratio: '16:10'
      highlightStyle: tomorrow
      highlightLines: true
      countIncrementalSlides: false
---

$$\newcommand\indep{\perp\!\!\!\perp}$$
$$\newcommand\nindep{\not\!\perp\!\!\!\perp}$$
```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  # Colors
  primary_color = "#2d68c4", 
  secondary_color = "#f2a900",
  link_color = "#f2a900",
  title_slide_text_color = "#f2a900",
  # Fonts
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Fira Mono"))
```

```{r setup, include=FALSE}
library(tidyverse)
library(ggdag)
```



## Introduction


The social sciences are experimenting what some authors have called a "credibility revolution" (Angrist and Pischke, 2010), the rise of "causal empiricism" (Samii, 2016), or simply a "causal revolution" (Pearl and MacKenzie, 2018).

The enormous progress in the last decades is associated with the development of two mathematical frameworks that allow researchers to transparently handle causal questions: the language of **Potential Outcomes** and the **Structural Causal Model**:

--

* Both languages logically equivalent but not equally expressive (Pearl, 2010)

--

  * Clearly separated research communities and lack of convergence

--

  * Researchers often argue about the *application domain* of POs and SCM (Imbens, 2020)

--

* Where we all agree: "**no causes in, no causes out**" (Nancy Cartwright)

  + Untestable and extra-statistical assumptions!
  
--

* Where we disagree: **Where the "causes in" come from?**

---

## Credibility in empirical research

Having the language to formulate our assumptions is one thing; 
--
judging if they are credible/plausible in a given application is a very different challenge.

--

* The risk of excessively relying on simply listing the assumptions needed for a "causal interpretation" of our results is real!

  + Think, for example, of early matching studies (Sekhon, 2009)
  
  + **knowledge-based** vs **convenience-based** assumptions (Petersen and van der Laan, 2014)

--

<br>

Different reactions from different research communities:

* **Draw your assumptions before your conclusions** (Hernan). 

  + Use DAGs to be transparent about your assumptions!

* **Stick to well-understood identification strategies**
  
  + Avoid DAGs to prevent overconfidence in your assumptions!

---

## Two positions

.pull-left[
  ### Design-based
  
  + Potential Outcomes
  
  + Bottom-up
  
  + Situation-specific
  
  + Quasi-experimental
  
  + Local effects
  
  + Model-free?
]

.pull-right[
  ### Model-based
  
  + Graphical models
  
  + Top-down
  
  + Problem-specific
  
  + Observational
  
  + Population effects
  
  + Design-free?
]


---

background-image: url(Inca_bridge.jpg)
background-size: cover


---

## The case for templates

> *Partly as a result of the focus on empirical examples, the econometrics literature has developed a small number of canonical settings where researchers view the specific causal models and associated statistical methods as well-established and understood. These causal models correspond to what is nowadays often referred to as* **identification strategies**
>>Guido Imbens (2020)

--

> *No one should ever write down a 100 variable DAG and do inference based on that. That would be an insane approach because the analysis would be totally impenetrable. Develop a research design where that 100 variable DAG trivially reduces to a familiar problem (e.g. IV!)*
>> Jason Abaluck (2020)


---

## The case for templates

Somewhat ironically, the utility of graphical models to aid causal inference has been questioned based on two different premises:

--

* DAG practitioners only offer toy examples! That's not useful for **actual research**
  
  + Credible designs (*identification strategies*) are well-understood without DAGs
  
  + DAGs might be helpful to build intuition, but only as temporary scaffolding 


> *This setting, where the critical assumption is ignorability or unconfoundedness, is so common and well studied, that merely referring to its label is probably sufficient for researchers to understand what is being assumed. Adding a DAG, or for that matter adding a proof that the average causal effect is identified in that setting, is superfluous because researchers are familiar with the setting and its implications*
>> Guido Imbens (2020)

--

* DAGs are useful when dealing with complex causal models (many variables, intricate relationships, over-time processes), but in those setting causal inference is a dead end

--

$\color{red}{\text{Graphical models are either too simple to be useful, or too complex to be credible!}}$

---

## Corollary: Credibility Ladder

> *Thus, we claim that strong causal inferences should rely on studies whose basic designs are associated with simple and credible causal graphs –well-implemented randomized trials and quasi- experiments, in particular RD designs, may meet this claim*
>> Steiner et al. (2017)

--

<br>

But credibility cannot be derived just by looking at the corresponding template DAG!

* The DAG is not always sufficient to encode all identifying assumptions

* The DAG says nothing about estimation issues

* The credibility we care about is of the **empirical analysis**, not an ideal template

  + Templates can be used to **claim** certain level of credibility
  
  + The gap between the template and the instance can be quite dramatic


---

## Actually existing uses of DAGs

In between, a very fruitful use of graphical models has been adopted among researchers. This also entails constructing **templates**, but in a very different sense:

* A graphical catalog of threats to validity (Matthay and Glymour, 2020)

* Identifying structural issues in empirical research
  
  + Contagion in networks
  
  + Multigenerational mobility
  
  + Police brutality
  
  + Education and mobility
  
  + Social genomics
  
  + COVID-19 risk factors
  
--

**These uses of graphical models are at a mid-level of abstraction; now I will argue that graphical models are also useful at a more granular, study-specific level of analysis**

---

## Moving beyond templates...

The choice between **model-free** as opposed to **model-based** causal inference is a false dilemma, diverting us from addressing the *mostly harmful* issue of **model-blind** research.

* Quasi-experimental designs usually imply a (series of compatible) model(s) 

  + We need to be explicit about them and discuss their plausibility

* To use graphical models:

  + is not opposed to design-based research (quasi-experiments, identification strategies)
  
  + one does not need to start with a totally general causal model of the entire process

--

<br>

$\color{red}{\text{Actual research lies in between the ideal and simplest templates, and intractably complex models!}}$
---

## The proposal: building DAGs bottom-up

An **agnostic** use of causal graphical models would start from the assumptions researchers are actually willing to make:

  + Construct the DAG inductively, without committing to a generative model **ex ante**
  
  + Reverse-engineering their implied causal model
  
  + Assess the credibility of the assumptions in the resulting model(s)
  
  + Systematically find implications to test
  

Departing from design templates, as common in practice, implies that assumptions are combined and their implications are not easily grasped by reference to the simplest case:

  + Mixed strategies (conditional-IV, conditional-RD, conditional-DD) require special attention
  
  + **A chain is not stronger than the weakest of its links** (SOO!)

---


class: center, middle

# Empirical Illustrations

---

## Community and the Crime Decline
### (Sharkey et al. 2017)


---

## Does Educational Equality increase Mobility?
### (Rauscher 2016)

---

##

---
##

---

## Conclusion

> *About 20 years ago, when asked in a meeting what can be done in observational studies to clarify the step from association to causation, Sir Ronald Fisher replied: “Make your theories elaborate.” The reply puzzled me at first, since by Occam’s razor, the advice usually given is to make theories as simple as is consistent with known data. What Sir Ronald meant, as subsequent discussion showed, was that when constructing a causal hypothesis one should envisage as many different consequences of its truth as possible, and plan observational studies to discover whether each of these is found to hold*
>> B. G. Cochran (cited in Rosenbaum, 1995)

---


class: center, middle

# Thank you!
---


