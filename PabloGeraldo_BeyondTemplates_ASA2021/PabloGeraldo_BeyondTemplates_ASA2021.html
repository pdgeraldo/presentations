<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Moving beyond templates of empirical research</title>
    <meta charset="utf-8" />
    <meta name="author" content="Pablo Geraldo (pdgeraldo@ucla.edu)" />
    <meta name="date" content="2021-08-09" />
    <script src="libs/header-attrs-2.7/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Moving beyond templates of empirical research
## (A guide to graphical models for the skeptic)
### Pablo Geraldo (<a href="mailto:pdgeraldo@ucla.edu" class="email">pdgeraldo@ucla.edu</a>)
### ASA, Quantitative Methodology Session
### August 9, 2021

---


`$$\newcommand\indep{\perp\!\!\!\perp}$$`
`$$\newcommand\nindep{\not\!\perp\!\!\!\perp}$$`





## Outline

* **Introduction**: between design- and model-based research

* 

---

## Introduction

&lt;br&gt;

The social sciences are experimenting what some authors have called a "credibility revolution" (Angrist and Pischke, 2010), the rise of "causal empiricism" (Samii, 2016), or simply a "causal revolution" (Pearl and MacKenzie, 2018).

The enormous progress in the last decades is associated with the development of two mathematical frameworks that allow researchers to transparently handle causal questions: the language of **Potential Outcomes** and the **Structural Causal Model**:

--

* Both languages logically equivalent but not equally expressive (Pearl, 2010)

--

  * Clearly separated research communities and lack of convergence

--

  * Researchers often argue about the *application domain* of POs and SCM (Imbens, 2020)

--

* Where we all agree: "**no causes in, no causes out**" (Nancy Cartwright)

  + Untestable and extra-statistical assumptions!
  
--

* Where we disagree: **Where the "causes in" come from?**

---

## Introduction

Having the language to formulate our assumptions is one thing; 
--
judging if they are credible in a given application is a very different challenge.

--

* The risk of excessively relying on simply listing the assumptions needed for a "causal interpretation" of our results is real!

  + Think, for example, of early matching studies (Sekhon, 2009)
  
  + **knowledge-based** vs **convenience-based** assumptions (Petersen and van der Laan, 2014)

--

Different reactions

---




class: center, middle

# Frameworks of Causal Inference
---


## Frameworks of Causal Inference

---



class: center, middle

# Templates of empirical research
---

## Templates of empirical research



---



class: center, middle

# Moving beyond templates...
---

## Moving beyond templates...

---

## Building DAGs from the bottom-up

* **Key idea**: The gap between "identification strategies" and actual empirical research can be quite dramatic!

---

## Community and the Crime Decline
### (Sharkey et al. 2017)


---

## Does Educational Equality increase Mobility?
### (Rauscher 2016)

---

##

---
##

---



class: center, middle

# Potential Outcomes
---


## Potential Outcomes


Introduced by Neyman (1923) in the context of experimental design. They remained only used in that context for decades!

&lt;br&gt;

* Imported and developed by Donald Rubin for observational studies (c. 1974)

* They are really great to clarify *what do we want to know* (**estimand**)

* This includes identifying *reasons for discrepancies* between what we observe and our estimand (**bias**) 

* They are great to formalize *what needs to be true*  for our estimand to be identified with a given *estimator* (**assumptions**)

* They are not-so-great to assess if our assumptions are plausible or defensible (more on this soon!)

---


## Potential Outcomes: Notation


Let's start with some definitions: 

&lt;br&gt;

`\(Y\)` is the outcome variable *as we observe it*

`\(X\)` is the variable whose effect we want to study (treatment, exposure)

`\(Y_x\)` is the potential outcome when we **set** `\(X=x\)`. For example, when `\(X \in \{0,1\}\)`:

  * `\(Y_1\)` is the potential outcome under "treatment"

  * `\(Y_0\)` is the potential outcome under "control"


---



## Potential Outcomes: Notation

You will find a lot of equivalent notations for potential outcomes. It could be confusing, but it is good to get practice working with different variants (at least if you want to read the papers!)

`$$Y(x) = Y_x = Y^x$$`

**Read it like this**: 

The value that the variable `\(Y\)` would take if we set the variable `\(X\)` to the value `\(x\)`.

.center[Can you ever observe any of those potential outcomes?]

--

**Consistency** (also known as SUTVA)

`$$X = x \rightarrow Y = Y_x$$`

For the binary treatment case, we have:

`$$Y = XY_1 + (1-X)Y_0$$`

What are the assumptions built in this notation? What type of dependence are we ruling out?

---

## Short activity (3 mins)

Researchers, at least in sociology, tend to formalize their effect of interest as **regression coefficients** (i.e., their hypothesis are formulated within a statistical model)

&lt;br&gt;
Potential outcomes offer a way to formalize what do we mean by a causal effect outside any statistical model. This allows us to clearly separate *what do we want* (a certain **estimand**), the statistical machinery to answer our question (an **estimator**) and the particular answer we get (our empirical **estimate**).

&lt;br&gt;
Lundberg, Johnson, and Stewart (2021) discuss in great detail this point. Absolutely worth reading! Ungated version [here](https://osf.io/preprints/socarxiv/ba67n/).

&lt;br&gt;
Take a moment to think in your own research:

* What **causal** question is relevant for you to study? 
* Can you formulate it using potential outcomes? 
* What are the assumptions your are making in this formalization?

---


## Potential Outcomes: The Science Table



One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` |
|----|---|---|-----|-------|--------|
| 1 | A | 1 | 1 | 1 | 0 |
| 2 | A | 0 | 0 | 0 | 0 |
| 3 | A | 0 | 0 | 1 |-1 |
| 4 | A | 1 | 1 | 0 | 1 |
| 5 | A | 1 | 1 | 1 | 0 |
| 6 | B | 0 | 1 | 0 | 1 |
| 7 | B | 0 | 1 | 0 | 1 |
| 8 | B | 0 | 0 | 0 | 0 |
| 9 | B | 1 | 0 | 1 |-1 |
| 10 |B | 1 | 1 | 1 | 0 |
]

.pull-right[
The basic calculation device (usually implicit) for that matter is the **science table**. Basically, the full schedule response of the potential outcomes under different treatment conditions
]


---




## Potential Outcomes: Average Treatment Effect

One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` |
|----|---|---|-----|-------|--------|
| 1 | A | 1 | 1 | 1 | 0 |
| 2 | A | 0 | 0 | 0 | 0 |
| 3 | A | 0 | 0 | 1 |-1 |
| 4 | A | 1 | 1 | 0 | 1 |
| 5 | A | 1 | 1 | 1 | 0 |
| 6 | B | 0 | 1 | 0 | 1 |
| 7 | B | 0 | 1 | 0 | 1 |
| 8 | B | 0 | 0 | 0 | 0 |
| 9 | B | 1 | 0 | 1 |-1 |
| 10 |B | 1 | 1 | 1 | 0 |
]

.pull-right[
`$$\text{ATE} = E(Y_{ai}) - E(Y_{bi})$$`
`$$(6/10) - (5/10) = \mathbf{\color{blue}{0.1}}$$`
]
---


## Potential Outcomes: difference in means

One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` |
|----|---|---|-----|-------|--------|
| 1 | A | 1 | 1 | . | . |
| 2 | A | 0 | 0 | . | . |
| 3 | A | 0 | 0 | . | . |
| 4 | A | 1 | 1 | . | . |
| 5 | A | 1 | 1 | . | . |
| 6 | B | 0 | . | 0 | . |
| 7 | B | 0 | . | 0 | . |
| 8 | B | 0 | . | 0 | . |
| 9 | B | 1 | . | 1 | . |
| 10 |B | 1 | . | 1 | . |
]

.pull-right[
`$$\text{ATE} = E(Y_{ai}) - E(Y_{bi})$$`
`$$(6/10) - (5/10) = \mathbf{\color{blue}{0.1}}$$`

&lt;br&gt;
`$$\text{diff-in-means} = E(Y_i|X=a) - E(Y_i|X=b)$$`
`$$(3/5)-(2/5) = \mathbf{\color{red}{0.2}}$$`
&lt;br&gt;
`$$\color{red}{\text{diff-in-means} \neq \text{ATE}}$$`

.center[But why?]
]
---


## Potential Outcomes: sources of bias

One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` |
|----|---|---|-----|-------|--------|
| 1 | A | 1 | 1 | . | . |
| 2 | A | 0 | 0 | . | . |
| 3 | A | 0 | 0 | . | . |
| 4 | A | 1 | 1 | . | . |
| 5 | A | 1 | 1 | . | . |
| 6 | B | 0 | . | 0 | . |
| 7 | B | 0 | . | 0 | . |
| 8 | B | 0 | . | 0 | . |
| 9 | B | 1 | . | 1 | . |
| 10 |B | 1 | . | 1 | . |
]

.pull-right[
`$$E(\text{diff-in-means})$$`
`$$= E(Y_i|X=a) - E(Y_i|X=b)$$`
`$$= E(Y_a|X=a) - E(Y_b|X=b)$$`
`$$= ATE +$$`
`$$(E[Y_b|X=a] - E[Y_b|X=b])+$$`
`$$(1-P[X])(ATT-ATC)$$`
`$$= \mathbf{\color{blue}{0.1}} + \color{red}{0.2 + (0.5)(-0.2) = \mathbf{0.2}}$$`
]
---



## Potential Outcomes: identification assumptions

One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` |
|----|---|---|-----|-------|--------|
| 1 | A | 1 | 1 | 1 | 0 |
| 2 | A | 0 | 0 | 0 | 0 |
| 3 | A | 0 | 0 | 1 |-1 |
| 4 | A | 1 | 1 | 0 | 1 |
| 5 | A | 1 | 1 | 1 | 0 |
| 6 | B | 0 | 1 | 0 | 1 |
| 7 | B | 0 | 1 | 0 | 1 |
| 8 | B | 0 | 0 | 0 | 0 |
| 9 | B | 1 | 0 | 1 |-1 |
| 10 |B | 1 | 1 | 1 | 0 |
]

.pull-right[
We need the following condition to be true:
$$
Y_x \indep X 
$$

Do we meet that condition here? No!
`$$(Y_{ai},Y_{bi}) \nindep X$$`

Because: 
`$$P(Y_a = y | X=a) \neq P(Y_a = y)$$`
`$$P(Y_b = y | X=b) \neq P(Y_b = y)$$`
]
---


## Potential Outcomes: identification assumptions

One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` | `\(W_i\)` |
|----|---|---|-----|-------|--------| --- |
| 1 | A | 1 | 1 | 1 | 0 | Quant |
| 2 | A | 0 | 0 | 0 | 0 | Quant |
| 3 | A | 0 | 0 | 1 |-1 | Qual |
| 4 | A | 1 | 1 | 0 | 1 | Quant |
| 5 | A | 1 | 1 | 1 | 0 | Qual |
| 6 | B | 0 | 1 | 0 | 1 | Qual |
| 7 | B | 0 | 1 | 0 | 1 | Quant |
| 8 | B | 0 | 0 | 0 | 0 | Qual |
| 9 | B | 1 | 0 | 1 |-1 | Qual |
| 10 |B | 1 | 1 | 1 | 0 | Quant |
]

.pull-right[
What about including another covariate `\(W\)`?

Does the following condition holds?
$$
Y_x \indep X | W
$$

Not quite either! But still "better" than before, right? Let's define:

`$$\text{ATE}_{W} = E(Y_a-Y_b|W=w)$$`
and the estimator
`$$\widehat{\text{ATE}}_{W} =$$` 
`$$E(Y_i|X=a,W=w) - E(Y_i|X=b,W=w)$$`
]
---



## Potential Outcomes: identification assumptions

One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` | `\(W_i\)` |
|----|---|---|-----|-------|--------| --- |
| 1 | A | 1 | 1 | 1 | 0 | Quant |
| 2 | A | 0 | 0 | 0 | 0 | Quant |
| 3 | A | 0 | 0 | 1 |-1 | Qual |
| 4 | A | 1 | 1 | 0 | 1 | Quant |
| 5 | A | 1 | 1 | 1 | 0 | Qual |
| 6 | B | 0 | 1 | 0 | 1 | Qual |
| 7 | B | 0 | 1 | 0 | 1 | Quant |
| 8 | B | 0 | 0 | 0 | 0 | Qual |
| 9 | B | 1 | 0 | 1 |-1 | Qual |
| 10 |B | 1 | 1 | 1 | 0 | Quant |
]

.pull-right[
`$$\widehat{\text{ATE}}_{W=quant} = 0.16$$`
`$$\widehat{\text{ATE}}_{W=qual} = 0.16$$`
`$$\widehat{\text{ATE}} = (0.5)(0.16) + (0.5)(0.16) = 0.16$$`
However, look a the true `\(\text{ATE}_W\)`:
`$$\text{ATE}_{W=quant} = -0.2$$`
`$$\text{ATE}_{W=qual} = 0.4$$`
`$$\text{ATE} = (0.5)(-0.2) + (0.5)(0.4) = \color{blue}{\mathbf{0.1}}$$`
]
---



## Potential Outcomes: how to assess our assumptions?

One advantage of PO is that we can treat them directly as random variables! So, everything we already know related to probability manipulation still applies here.

.pull-left[
| Unit | `\(X_i\)` | `\(Y_i\)` | `\(Y_{ai}\)` | `\(Y_{bi}\)` | `\(\tau_i\)` | `\(W_i\)` |
|----|---|---|-----|-------|--------| ---|
| 1 | A | 1 | 1 | . | . | Quant |
| 2 | A | 0 | 0 | . | . | Quant |
| 3 | A | 0 | 0 | . | . | Qual |
| 4 | A | 1 | 1 | . | . | Quant |
| 5 | A | 1 | 1 | . | . | Qual |
| 6 | B | 0 | . | 0 | . | Qual |
| 7 | B | 0 | . | 0 | . | Quant |
| 8 | B | 0 | . | 0 | . | Qual |
| 9 | B | 1 | . | 1 | . | Qual |
| 10 |B | 1 | . | 1 | . | Quant |
]

.pull-right[
In general, we rely on **extra-statistical assumptions** about the data generating process to claim causal identification.

&lt;br&gt;
&gt;"No causes in, no cases out"
&gt;&gt; Nancy Cartwright

&lt;br&gt;

Is there a way to design an study in which we know, **by design**, that the needed assumptions hold?
]
---


class: center, middle

# Randomized experiments

---

## Why randomization

If we want to **predict under interventions**, then the best way to do it is **interveening**!

&lt;br&gt;
Random assignment (more specifically, RCTs) has been called the **gold standard** for causal inference: it guarantees the necessary assumptions for causal inference hold by design.

&lt;br&gt;
When unfesible, imagining a hypothetical experiment still offers a useful benchmark to assess the validity of causal claims, and even to clarify what do we mean by a particular causal effect.

&lt;br&gt;
Experiments come in many different flavours: lab, field, survey, and even quasi-experimentss!

&lt;br&gt;
Here we will only scratch the surface of social science experiments: the idea is to get you interested and point you to the resources out there! Maybe sometime soon you will be running your own experiment! (Or at least someone else's experiment)


---

## Short activity (3 mins)

Sometimes it is hard to imagine an experiment that would be relevant for the type of questions we care about. 

&lt;br&gt;
Some people even say (and I for sure partially agree!) that experiments tend to emphasize "small" versus "big" questions, promoting incremental/testable policies. 

&lt;br&gt;
However, there are tons of examples of researchers using experiments to address important, **big** and difficult questions. **Do you know of any example?**

&lt;br&gt;
Take a moment to check the syllabus of UCLA professor Graeme Blair's Experimental Design class [here](https://graemeblair.com/teaching/UCLA_PS200E_Syllabus.pdf). He put together a list of experiments conducted by UCLA faculty, and by graduate students.

.center[**Any comments?**]

---

## Why randomization 
### (more formally)

We already saw that we can identify the causal effect of `\(X\)` on `\(Y\)` if the treatment assignment is independent of the potential outcomes. Formally `$$(Y_x,Y_{x^*}) \indep X$$`

Recall the diff-in-means decomposition we review earlier. Given the **ignorability** of the treatment assignment, we have can further write it as:

By consistency

`$$E(Y_i|X=x) - E(Y_i|X=x^*) = E(Y_x|X=x) - E(Y_{x^*}|X=x^*)$$`
With some algebra

`$$= E(Y_x - Y_{x^*}) + (E[Y_{x^*}|X=x] - E[Y_{x^*}|X=x^*])+(1-P[X])(ATT-ATC)$$`
By ignorability, this simplifies to

`$$E(Y_x - Y_{x^*}) = ATE$$`

---

## Forms of validity

Traditionally, researchers argue about the validity of a study's causal conclusion (and, more generally, about the validity of different research designs) based on the potential biases that pose **threats to validity**. Check [this](https://journals.lww.com/epidem/Fulltext/2020/05000/A_Graphical_Catalog_of_Threats_to_Validity_.11.aspx) amazing paper by Matthay and Glymour for a review.

&lt;br&gt;
We reviewed the bias in the difference-in-means estimator: baseline differences (under the control condition), and differential response to the treatment (under the exposure condition).

&lt;br&gt;
But when we randomize an exposure, we know that who ends up in each treatment arm has nothing to do with their potential outcomes!

&lt;br&gt;
This is why we generally say that experiments are great for **internal validity**: among the people that participated in our study, we can rule out systematic sources of bias. 

&lt;br&gt;
However, this does not imply that our results are **externally valid**, i.e., that they apply to people outside our study! We need further assumptions to move from one to another.

---

## How to randomize?

Many times, we use randomization not just for identification (**ignorability**), but also for estimation! 

&lt;br&gt;
If we assume the potential outcomes are fixed, and the only thing that varies is the treatment assignment scheme, we can derive a **permutation distribution** and use it for inference.

&lt;br&gt;
How much dispersion (i.e. uncertainty) is in our distribution will be affected by **the level** at which randomization (or, more precisely, the treatment) happens: is it at the individual level? or at a cluster/group level?

* The more the aggregation, the more uncertainty. So why would we want to randomize at the cluster level?

Conditional randomization (i.e., blocking) increase efficiency, when we have variables that are highly predictive of the outcome of interest

* One extreme of this is randomization in matched pairs: for each pair of individual with similar covariates, we randomly assign one to treatment and one to control.



---

## Types of experiments

&lt;br&gt;
* **Laboratory experiments**: Usually conducted with a small sample (of undergraduate psychology students), many times involving games in a computer. Helpful for cognitive/behavioral questions.

* **Field experiments**: In order to obtain more *externally valid* results, experiments conducted in the field (i.e., under real-world conditions) are the way to go. Definitely more expensive though. Audit studies are a particular type of field experiment.

* **Survey experiments**: One can randomize treatment conditions *in a survey* to evaluate how participants change their responses based on certain stimulus. Vignettes and list experiments are examples of this approach.

* **(Bonus) Quasi-experiments**: Researchers usually call quasi-experiments to real-world situations that offer as-if random variation in a treatment of interest. For example, earthquakes, change in laws, date of birth, etc. 

---

## Additional Resources 

&lt;br&gt;
### Online learning

* A selected and annotated bibliography on causality [here](https://www.pablogeraldo.com/pdf/GeraldoBrand_2020_Causality.pdf).

* J-PAL research resources [here](https://www.povertyactionlab.org/research-resources?view=toc)

* EGAP methods guides [here](https://egap.org/methods-guides/)

### Textbooks

* Gerber and Green (2012) Field Experiments: Design, Analysis, and Interpretation (check [here](https://www.amazon.com/Field-Experiments-Design-Analysis-Interpretation/dp/0393979954/ref=sr_1_11?dchild=1&amp;keywords=gerber+green&amp;qid=1624466782&amp;sr=8-11))


---

## Where to conduct survey experiments
### (by Natasha Quadlin)

* Time-Sharing Experiments for the Social Sciences: https://tessexperiments.org/

  Proposals and materials for all prior studies: https://tessexperiments.org/previousstudies.html
	
  (Pros: nationally representative, free, fast; Cons: must submit proposal)
	
* Qualtrics: https://www.qualtrics.com/
	
  (Pros: decent sample; Cons: can be data quality issues, expensive)

* Prolific Academic: https://www.prolific.co/
	
	(Pros: relatively inexpensive, lots of subsamples; Cons: can be data quality issues)

* Amazon Mechanical Turk: https://www.mturk.com/
	
	(Pros: fast, cheap; Cons: opt-in sampling, can be data quality issues)


---

class: center, middle

![xkcd classic](https://imgs.xkcd.com/comics/correlation.png)

---

class: center, middle

# Activity

---

## Afternoon activity

Meet with your project group, and think in a research question that you could possibly address using an experimental design:

* What is your research question?

* What is your **estimand**? (effect of what? among whom?)

* What type of experiment would you conduct? (lab? field? survey?)

* What would be the level of your randomization? (individual? cluster? why?)

Using your answers to the question above, propose and design a (survey) experiment that could help answering your research questions.

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:10",
"highlightStyle": "tomorrow",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
